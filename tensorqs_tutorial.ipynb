{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxvsh/LearningPytorch/blob/main/tensorqs_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tVnOjvlAJqdG"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb-GGHdkJqdG"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\|\n",
        "[Quickstart](quickstart_tutorial.html) \\|\\| **Tensors** \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Tensors\n",
        "=======\n",
        "\n",
        "Tensors are a specialized data structure that are very similar to arrays\n",
        "and matrices. In PyTorch, we use tensors to encode the inputs and\n",
        "outputs of a model, as well as the model's parameters.\n",
        "\n",
        "Tensors are similar to [NumPy's](https://numpy.org/) ndarrays, except\n",
        "that tensors can run on GPUs or other hardware accelerators. In fact,\n",
        "tensors and NumPy arrays can often share the same underlying memory,\n",
        "eliminating the need to copy data (see\n",
        "`bridge-to-np-label`{.interpreted-text role=\"ref\"}). Tensors are also\n",
        "optimized for automatic differentiation (we\\'ll see more about that\n",
        "later in the [Autograd](autogradqs_tutorial.html) section). If you're\n",
        "familiar with ndarrays, you'll be right at home with the Tensor API. If\n",
        "not, follow along!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PzOGJBijJqdI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AGnr6jWJqdJ"
      },
      "source": [
        "Initializing a Tensor\n",
        "=====================\n",
        "\n",
        "Tensors can be initialized in various ways. Take a look at the following\n",
        "examples:\n",
        "\n",
        "**Directly from data**\n",
        "\n",
        "Tensors can be created directly from data. The data type is\n",
        "automatically inferred.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gzoWeFnmJqdJ"
      },
      "outputs": [],
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_data)"
      ],
      "metadata": {
        "id": "Xe6RxR8oLsdr",
        "outputId": "d466526c-5f72-402e-96b6-0bf08ca7432e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGO1fyv9JqdJ"
      },
      "source": [
        "**From a NumPy array**\n",
        "\n",
        "Tensors can be created from NumPy arrays (and vice versa - see\n",
        "`bridge-to-np-label`{.interpreted-text role=\"ref\"}).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "S2P9QkL1JqdK"
      },
      "outputs": [],
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3kzDDoyJqdK"
      },
      "source": [
        "**From another tensor:**\n",
        "\n",
        "The new tensor ***retains the properties*** (shape, datatype) of the argument\n",
        "tensor, unless explicitly overridden.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "imPVH_ziJqdK",
        "outputId": "7c25d677-d7d7-4759-8a40-a329da9a42c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.3840, 0.1407],\n",
            "        [0.4471, 0.4058]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# create a tensor of ones that is similar to x_data in shape\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "# create a tensor of random numbers that is similar to x_data in shape\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another Example**"
      ],
      "metadata": {
        "id": "n9Iklk5MMNhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
        "print(x1)\n",
        "\n",
        "print(torch.ones_like(x1))"
      ],
      "metadata": {
        "id": "ws6by3oOMTyi",
        "outputId": "ff6c8843-e00d-4491-c167-deac86327f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJh2RyM8JqdL"
      },
      "source": [
        "**With random or constant values:**\n",
        "\n",
        "`shape` is a tuple of tensor dimensions. In the functions below, it\n",
        "determines the dimensionality of the output tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Yb18vjQbJqdL",
        "outputId": "e8f6000e-d85a-4f53-f7e4-1c3fcd9cb5cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.0580, 0.1116, 0.5049],\n",
            "        [0.4923, 0.5728, 0.3348]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape) # create a tensor of random numbers of the given shape\n",
        "ones_tensor = torch.ones(shape) # create a tensor of ones of the given shape\n",
        "zeros_tensor = torch.zeros(shape) # create a tensor of zeros of the given shape\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.rand(3,3,3) # creates a tensor of random elements (of shape 3x3x3)"
      ],
      "metadata": {
        "id": "QW66s5iaM8U6",
        "outputId": "bce6bceb-2e4e-48da-a33f-836ed9937ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.2487, 0.0639, 0.0293],\n",
              "         [0.5900, 0.6302, 0.0088],\n",
              "         [0.5402, 0.6606, 0.8355]],\n",
              "\n",
              "        [[0.4939, 0.1492, 0.6822],\n",
              "         [0.2111, 0.7080, 0.2703],\n",
              "         [0.8148, 0.3172, 0.3254]],\n",
              "\n",
              "        [[0.8079, 0.8336, 0.4361],\n",
              "         [0.9482, 0.6404, 0.2895],\n",
              "         [0.8447, 0.6464, 0.3875]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg9QoqqpJqdL"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lD6bfMsJqdM"
      },
      "source": [
        "Attributes of a Tensor\n",
        "======================\n",
        "\n",
        "Tensor attributes describe their **shape**, **datatype**, and the **device** on\n",
        "which they are stored.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "soWGu2x2JqdM",
        "outputId": "41653ae1-a5b7-403a-d757-13891d7cfcb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByK7U-rBJqdM"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2uxW2wUJqdM"
      },
      "source": [
        "Operations on Tensors\n",
        "=====================\n",
        "\n",
        "Over 100 tensor operations, including arithmetic, linear algebra, matrix\n",
        "manipulation (transposing, indexing, slicing), sampling and more are\n",
        "comprehensively described\n",
        "[here](https://pytorch.org/docs/stable/torch.html).\n",
        "\n",
        "Each of these operations can be run on the **GPU** (at typically higher\n",
        "speeds than on a CPU). If you're using Colab, allocate a GPU by going to\n",
        "Runtime \\> Change runtime type \\> GPU.\n",
        "\n",
        "By default, tensors are created on the CPU. We need to explicitly move\n",
        "tensors to the GPU using `.to` method (after checking for GPU\n",
        "availability). Keep in mind that copying large tensors across devices\n",
        "can be expensive in terms of time and memory!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DRBVZ2cMJqdM"
      },
      "outputs": [],
      "source": [
        "# We move our tensor to the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    tensor = tensor.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor.device)\n",
        "# now it is stored on a GPU if a run time with GPU was selected"
      ],
      "metadata": {
        "id": "opdiAatvN6cV",
        "outputId": "be9d4b6f-7ab0-4d54-af74-a32c0ba88e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9gg0W29JqdM"
      },
      "source": [
        "Try out some of the operations from the list. If you\\'re familiar with\n",
        "the NumPy API, you\\'ll find the Tensor API a breeze to use.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwKAmu65JqdN"
      },
      "source": [
        "**Standard numpy-like indexing and slicing:**\n",
        "\n",
        "`tensor[i, j]` refers to the i-th row and the j-th column.\n",
        "Also, for slicing operations, the first index is used for rows, and the second one is used for columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "99LteqeEJqdN",
        "outputId": "1182e5cd-e317-42e9-aabe-1c02986a084b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "tensor = torch.ones(4, 4)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:, 0]}\")\n",
        "print(f\"Last column: {tensor[:, -1]}\")\n",
        "\n",
        "# set the second column of this 4x4 ones tensor to 0\n",
        "tensor[:,1] = 0\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Another Example**"
      ],
      "metadata": {
        "id": "jFiCjLQmOvdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = torch.rand(3,3)\n",
        "print(x2)"
      ],
      "metadata": {
        "id": "Gz9BB8baOvBS",
        "outputId": "8cc351ce-2e8d-403e-c675-91be8746afbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3244, 0.5773, 0.2320],\n",
            "        [0.9265, 0.6066, 0.8800],\n",
            "        [0.5651, 0.9281, 0.5102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Second column: \", x2[:,1])\n",
        "print(\"Last row: \", x2[2])"
      ],
      "metadata": {
        "id": "IUl2V5x-PM9D",
        "outputId": "2d9dc5b2-f6b9-433e-8d63-a67150880ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second column:  tensor([0.5773, 0.6066, 0.9281])\n",
            "Last row:  tensor([0.5651, 0.9281, 0.5102])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk0wvT5VJqdN"
      },
      "source": [
        "**Joining tensors** You can use `torch.cat` to concatenate a sequence of\n",
        "tensors along a given dimension. See also\n",
        "[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html),\n",
        "another tensor joining operator that is subtly different from\n",
        "`torch.cat`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatenation of tensors using `torch.cat`:\n",
        "\n",
        "It takes a sequence of tensors and concatenates them along a given dimension.\n",
        "You can concatenate them along the vertical dimension (dim=0), or along the horizontal dimension (dim=1)"
      ],
      "metadata": {
        "id": "KhBgxf9VPoz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(example_tensor)"
      ],
      "metadata": {
        "id": "2gIua5mtSF3t",
        "outputId": "790c3a83-bac7-4bcf-ddf6-3a2d18289413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QBiWR-DqJqdN",
        "outputId": "0a51d851-bbab-4371-a4e0-ff364d5b9b37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3, 1, 2, 3, 1, 2, 3],\n",
            "        [4, 5, 6, 4, 5, 6, 4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "t1 = torch.cat([example_tensor, example_tensor, example_tensor], dim=1) # concatenates the tensors along the horizontal dimension\n",
        "print(t1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([example_tensor, example_tensor, example_tensor], dim=0) # concatenates the tensors along the vertical dimension\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "UZkgOReUW1cV",
        "outputId": "04f0e2f2-4782-4532-851f-225938a5df53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stacking tensors using `torch.stack`\n",
        "\n",
        "Can stack tensors using the `torch.stack` method. For example:"
      ],
      "metadata": {
        "id": "QRLjL9SBRxlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack((example_tensor, example_tensor)) # stacks the tensors on top of each other"
      ],
      "metadata": {
        "id": "HNtyGrUZX3O9",
        "outputId": "3acc4c08-33e6-4b3c-ab80-0fdda0c8dd81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [4, 5, 6]],\n",
              "\n",
              "        [[1, 2, 3],\n",
              "         [4, 5, 6]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUrsERB4JqdN"
      },
      "source": [
        "**Arithmetic operations**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LHPRrLGGJqdN",
        "outputId": "149e3036-e827-4d3b-83b3-0a39ab2cdf08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "# ``tensor.T`` returns the transpose of a tensor\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "\n",
        "z3 = torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor, out=z3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWFkJOGVJqdN"
      },
      "source": [
        "**Single-element tensors** If you have a one-element tensor, for example\n",
        "by aggregating all values of a tensor into one value, you can convert it\n",
        "to a Python numerical value using `item()`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Okh558m9JqdN",
        "outputId": "8c26050a-bd26-4d66-e360-80d71b7716ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.) <class 'torch.Tensor'>\n",
            "12.0 <class 'float'>\n"
          ]
        }
      ],
      "source": [
        "agg = tensor.sum()\n",
        "print(agg, type(agg)) # this is a one-element tensor\n",
        "\n",
        "agg_item = agg.item() # converted the 1 element tensor to a numerical python value\n",
        "print(agg_item, type(agg_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHJDotZkJqdO"
      },
      "source": [
        "**In-place operations** Operations that store the result into the\n",
        "operand are called in-place. They are denoted by a `_` suffix. For\n",
        "example: `x.copy_(y)`, `x.t_()`, will change `x`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "HRvxVxt6JqdO",
        "outputId": "ad29a800-ec6d-463c-a7ec-63fa10a1d40a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]]) \n",
            "\n",
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]])\n"
          ]
        }
      ],
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lji5WA-GJqdO"
      },
      "source": [
        "<div style=\"background-color: #54c7ec; color: #fff; font-weight: 700; padding-left: 10px; padding-top: 5px; padding-bottom: 5px\"><strong>NOTE:</strong></div>\n",
        "<div style=\"background-color: #f3f4f7; padding-left: 10px; padding-top: 10px; padding-bottom: 10px; padding-right: 10px\">\n",
        "<p>In-place operations save some memory, but can be problematic when computing derivatives because of an immediate loss of history. <strong>Hence, their use is discouraged.</strong></p>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OqdrQ6FJqdO"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c08J-oWQJqdO"
      },
      "source": [
        "Bridge with NumPy {#bridge-to-np-label}\n",
        "=================\n",
        "\n",
        "Tensors on the CPU and NumPy arrays can share their underlying memory\n",
        "locations, and changing one will change the other.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMxnWEpmJqdO"
      },
      "source": [
        "Tensor to NumPy array\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "aRuOG052JqdO",
        "outputId": "ce50e978-776b-4dac-e1ee-26f9555baf8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYRQPHHXJqdO"
      },
      "source": [
        "A change in the tensor reflects in the NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "itxROZdtJqdP",
        "outputId": "5f98d547-a38d-4e39-8602-e9540ec7fa2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrZd7sUnJqdP"
      },
      "source": [
        "NumPy array to Tensor\n",
        "=====================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "shOJlavvJqdP"
      },
      "outputs": [],
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP-x88NiJqdP"
      },
      "source": [
        "Changes in the NumPy array reflects in the tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "eZVfOsP9JqdP",
        "outputId": "d5b817eb-bc0b-40aa-f9a9-7a04877e7a00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
            "n: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}